#' Get prior year max date from a data frame or time series. This is especially useful for weekly time series when YTD PYTD calculations aren't as straightforward.
#' Transformer to collapse variables of length 2 or more
#'
#' @param regex Expression to find in the template text
#' @param ...
#'
#' @noRd
collapse_transformer <- function(regex = "$", ...) {
  function(text, envir) {
    collapse <- grepl(regex, text)
    if (collapse) {
      text <- sub(regex, "", text)
    }
    res <- glue::identity_transformer(text, envir)
    if (collapse) {
      return(glue::glue_collapse(res, ...))
    } else {
      return(res)
    }
  }
}

#' For example if "2022-05-23" is max date in weekly aggregates time series data frame is doesn't meant that PYTD will end exactly a year ago - we need to calculate number of weeks passed to get the calculation right
#'
#' @param df Data frame or tibble with date column
#' @param frequency Date frequency
#'
#' @return \code{Date} object
#' @noRd
get_py_date <- function(df, frequency = NULL) {

  df <- df %>%
    dplyr::ungroup()

  if (is.null(frequency)) {
    frequency <- get_frequency(df)
  }

  date_field <- df %>%
    dplyr::select_if(lubridate::is.timepoint) %>%
    names() %>%
    magrittr::extract2(1)

  # rename to avoid ambiguous objects to week - name of the column and function
  if (date_field == "week") {
    df <- df %>%
      dplyr::rename(date_column = week)

    date_field <- "date_column"
  }

  if (length(date_field) == 0) stop("data frame must contain one date column")

  max_date <- max(df[[date_field]])
  max_year <- lubridate::year(max_date)

  if (frequency == "week") {
    df_weekly <- df %>%
      dplyr::select(dplyr::all_of(date_field)) %>%
      unique() %>%
      dplyr::arrange(base::get(date_field)) %>%
      dplyr::mutate(
        week = lubridate::week(base::get(date_field)),
        year = lubridate::year(base::get(date_field))
      )

    max_week <- df_weekly %>%
      dplyr::filter(base::get(date_field) == max_date) %>%
      dplyr::select(week) %>%
      as.numeric()

    py_date <- df_weekly %>%
      dplyr::filter(year == max_year-1,
                    week == max_week) %>%
      dplyr::select(dplyr::all_of(date_field)) %>%
      as.matrix() %>%
      as.Date()

    if (length(py_date) == 0) py_date <- max_date - lubridate::years(1)

  } else {
    py_date <- max_date - lubridate::years(1)
  }

  return(py_date)
}


#' Calculate YTD volume from raw dataset
#'
#' @param df data frame or tibble to be filtered (raw, not generated by gen_table)
#' @param measure variable to be analyzed
#' @param date list of columns to apply filter
#' @param summarization summarization field in series, one of the following methods - 'count', 'average', 'sum'
#' @param current_year add current year to avoid situation when some of the groups don't have data in latest periods and current year is estimated incorrectly
#' @param cy_date date cutoff for current year if different from the max date of the supplied data frame
#'
#' @return \code{numeric} value
#' @noRd
ytd_volume <- function(
    df,
    measure = NULL,
    date = NULL,
    summarization = "sum",
    current_year = NULL,
    cy_date = NULL) {


  # Table must be a data.frame and have at least one row
  if (!is.data.frame(df)) stop("df must be a data.frame or tibble")
  if (nrow(df) == 0) stop("df must have at least one row, execution is stopped")

  # Getting the right data types
  df <- df %>%
    dplyr::ungroup() %>%
    tibble::as_tibble() %>%
    readr::type_convert(na = c("")) %>%
    suppressMessages() %>%
    suppressWarnings()

  # Summarization Assertion
  if (!summarization %in% c("sum", "count", "average")) stop("summarization must of be one of: 'sum', 'count' or 'mean'.")

  # Measure, Date and Dimensions Assertion
  if (!is.null(measure)) {
    if (!measure %in% names(df)) stop("measure must a column in the dataset")
  } else {
    # If measure isn't supplied get the first numerical column from it
    measure <- df %>%
      dplyr::select_if(is.numeric) %>%
      names() %>%
      magrittr::extract2(1)
  }

  # Get Date
  if (!is.null(date)) {
    if (!date %in% names(df)) stop("date must a column in the dataset")

    df <- df %>%
      dplyr::mutate(!!date := as.Date(base::get(date)))

    if (!lubridate::is.timepoint(df[[date]])) stop("'date' must be a date column in the dateset")
  } else {
    # Getting the first date field available
    date <- df %>%
      dplyr::select_if(lubridate::is.timepoint) %>%
      names() %>%
      magrittr::extract2(1) # Get the first date field available
  }

  # Current Year's Date
  if (is.null(cy_date)) {
    cy_date <- max(df[[date]])
  } else {
    cy_date <- as.Date(cy_date)
  }

  # Current year assertion
  if (!is.null(current_year) && current_year != lubridate::year(max(df[[date]]))) {
    current_year <- suppressWarnings(as.numeric(current_year))
    if (is.na(current_year)) stop("current_year argument must be numeric or convertable to numeric like 2022 or '2022' ")
  } else {
    current_year <- lubridate::year(cy_date)
  }

  cy_volume <- df %>%
    dplyr::mutate(year = lubridate::year(base::get(date))) %>%
    dplyr::filter(year == current_year,
                  base::get(date) <= cy_date) %>%
    dplyr::summarise(value = switch(
      summarization,
      "sum" = sum(base::get(measure),na.rm = TRUE),
      "count" = length(unique(base::get(measure))),
      "average" = mean(base::get(measure),na.rm = TRUE)
    )
    )  %>%
    as.numeric()

  return(cy_volume)
}

#' Calculate PYTD volume from raw dataset
#'
#' @param df data frame or tibble to be filtered (raw, not generated by gen_table)
#' @param measure variable to be analyzed
#' @param date list of columns to apply filter
#' @param summarization summarization field in series, one of the following methods - 'count', 'mean', 'sum'
#' @param current_year add current year to avoid situation when some of the groups don't have data in latest periods and current year is estimated incorrectly
#' @param py_date date to be used for PYTD calculation, if NULL then \code{get_py_date()} will be used by default
#'
#' @return \code{numeric} value
#' @noRd
pytd_volume <- function(
    df,
    measure = NULL,
    date = NULL,
    summarization = "sum",
    current_year = NULL,
    py_date = NULL) {

  # Table must be a data.frame and have at least one row
  if (!is.data.frame(df)) stop("df must be a data.frame or tibble")
  if (nrow(df) == 0) stop("df must have at least one row, execution is stopped")

  # Getting the right data types
  df <- df %>%
    dplyr::ungroup() %>%
    tibble::as_tibble() %>%
    readr::type_convert(na = c("")) %>%
    suppressMessages() %>%
    suppressWarnings()

  # Summarization Assertion
  if (!summarization %in% c("sum", "count", "average")) stop("summarization must of be one of: 'sum', 'count' or 'mean'.")

  # Measure, Date and Dimensions Assertion
  if (!is.null(measure)) {
    if (!measure %in% names(df)) stop("measure must a column in the dataset")
  } else {
    # If measure isn't supplied get the first numerical column from it
    measure <- df %>%
      dplyr::select_if(is.numeric) %>%
      names() %>%
      magrittr::extract2(1)
  }

  # Get Date
  if (!is.null(date)) {
    if (!date %in% names(df)) stop("date must a column in the dataset")

    df <- df %>%
      dplyr::mutate(!!date := as.Date(base::get(date)))

    if (!lubridate::is.timepoint(df[[date]])) stop("'date' must be a date column in the dateset")
  } else {
    # Getting the first date field available
    date <- df %>%
      dplyr::select_if(lubridate::is.timepoint) %>%
      names() %>%
      magrittr::extract2(1) # Get the first date field available
  }

  # PY Date
  if (is.null(py_date)) {
    py_date <- get_py_date(df)
  } else {
    py_date <- as.Date(py_date)
  }

  # Current year assertion
  if (!is.null(current_year) && current_year != lubridate::year(max(df[[date]]))) {

    current_year <- suppressWarnings(as.numeric(current_year))

    if (is.na(current_year)) {
      stop("current_year argument must be numeric or convertable to numeric like 2022 or '2022' ")
    }

    # we need py_date since we don't have current year's max date here.
    previous_year <- current_year - 1

    py_date <- as.Date(py_date)
  } else {
    previous_year <- lubridate::year(py_date)
  }

  py_volume <- df %>%
    dplyr::mutate(year = lubridate::year(base::get(date))) %>%
    dplyr::filter(year == previous_year,
                  base::get(date) <= py_date) %>%
    dplyr::summarise(value = switch(
      summarization,
      "sum" = sum(base::get(measure),na.rm = TRUE),
      "average" = mean(base::get(measure),na.rm = TRUE),
      "count" = length(unique(base::get(measure)))
    )
    ) %>%
    as.numeric()

  return(py_volume)
}

#' Create a list with descriptive outliers
#'
#' @param df Data frame of tibble, can be aggregated or raw
#' @param measure Numeric measure column
#' @param dimension Dimension within which the outlying patterns should be found
#' @param total Total measure value passed
#' @param summarization Approach for data summarization/aggregation - 'sum', 'count' or 'average'
#' @param coverage Portion of variability to be covered by narrative, 0 to 1
#' @param coverage_limit Maximum number of elements to be narrated, overrides
#' coverage to avoid extremely verbose narrative creation
#'
#' @noRd
get_descriptive_outliers <- function(
    df,
    dimension,
    measure,
    total = NULL,
    summarization = "sum",
    coverage = 0.5,
    coverage_limit = 5) {

  table <- df %>%
    dplyr::group_by(dplyr::across(dplyr::all_of(dimension))) %>%
    dplyr::summarise(!!measure := switch(
      summarization,
      "sum" = sum(base::get(measure), na.rm = TRUE),
      "count" = dplyr::n_distinct(base::get(measure), na.rm = TRUE),
      "average" = mean(base::get(measure), na.rm = TRUE)
    )
    ) %>%
    dplyr::arrange(dplyr::desc(base::get(measure)))

  if (summarization %in% c("sum", "count")) {

    if (is.null(total)) {
      total <- table %>%
        dplyr::summarise(total = sum(base::get(measure), na.rm = TRUE)) %>%
        as.numeric()
    }

    table <- table %>%
      dplyr::mutate(share = base::get(measure)/total) %>%
      dplyr::mutate(cum_share = cumsum(share)) %>%
      dplyr::filter(cumsum(dplyr::lag(cum_share >= coverage, default = FALSE)) == 0) %>%
      dplyr::slice(1:coverage_limit)

    # For a single dimension we skip to the next level
    if (nrow(table) == 1 && table$cum_share[1] == 1) return(NULL)

  } else if (summarization %in% c("average")) {

    if (is.null(total)) {
      total <- table %>%
        dplyr::summarise(total = mean(base::get(measure), na.rm = TRUE)) %>%
        as.numeric()
    }

    table <- table %>%
      dplyr::mutate(share = base::get(measure)/total - 1) %>%
      dplyr::arrange(dplyr::desc(abs(share))) %>%
      dplyr::mutate(cum_share = cumsum(abs(share))/(max(share) - min(share))) %>%
      dplyr::filter(cumsum(dplyr::lag(cum_share >= coverage*2, default = FALSE)) == 0) %>%
      dplyr::slice(1:coverage_limit)
  }

  n_outliers <- nrow(table)

  outlier_levels <- table %>%
    dplyr::select(dplyr::all_of(dimension)) %>%
    as.matrix() %>%
    as.character()

  outlier_values <- table %>%
    dplyr::select(dplyr::all_of(measure)) %>%
    as.matrix() %>%
    as.numeric() %>%
    round(1)

  outlier_values_p <- table %>%
    dplyr::mutate(share = round(share * 100, 1)) %>%
    dplyr::select(share) %>%
    as.matrix() %>%
    as.numeric() %>%
    paste("%")

  output <- list(
    n_outliers = n_outliers,
    outlier_levels = outlier_levels,
    outlier_values = outlier_values,
    outlier_values_p = outlier_values_p
  )

  return(output)
}

#' Create a list with descriptive outliers
#'
#' @param df Data frame of tibble, can be aggregated or raw
#' @param measure Numeric measure column
#' @param total Total measure value passed
#' @param summarization Approach for data summarization/aggregation - 'sum', 'count' or 'average'
#' @param dimension Dimension within which the outlying patterns should be found
#' @param coverage Portion of variability to be covered by narrative, 0 to 1
#' @param coverage_limit Maximum number of elements to be narrated, overrides
#' coverage to avoid extremely verbose narrative creation
#'
#' @noRd
get_trend_outliers <- function(
    df,
    dimension,
    measure,
    total = NULL,
    summarization = "sum",
    coverage = 0.5,
    coverage_limit = 5) {

  table <- df %>%
    dplyr::group_by(dplyr::across(dplyr::all_of(dimension))) %>%
    tidyr::nest() %>%
    dplyr::mutate(
      curr_volume = purrr::map_dbl(data, ytd_volume,
                                   summarization = summarization,
                                   measure = measure),
      prev_volume = purrr::map_dbl(data, pytd_volume,
                                   summarization = summarization,
                                   measure = measure),
      change = curr_volume - prev_volume,
      change_p = paste(round(change/prev_volume*100, 2), "%"),
      abs_change = abs(change),
      trend = ifelse(change > 0, "increase", "decrease")
    ) %>%
    dplyr::ungroup() %>%
    dplyr::select(-data) %>%
    dplyr::arrange(-abs_change)

  if (summarization %in% c("sum", "count")) {

    # if (is.null(total)) {
    #   curr_volume <- table %>%
    #     dplyr::summarise(total = sum(curr_volume, na.rm = TRUE)) %>%
    #     as.numeric()
    #
    #   prev_volume <- table %>%
    #     dplyr::summarise(total = sum(prev_volume, na.rm = TRUE)) %>%
    #     as.numeric()
    #
    #   change <- curr_volume - prev_volume
    # }

    table <- table %>%
      dplyr::mutate(share = abs_change/sum(abs_change)) %>%
      dplyr::mutate(cum_share = cumsum(share)) %>%
      dplyr::filter(cumsum(dplyr::lag(cum_share >= coverage, default = FALSE)) == 0) %>%
      dplyr::slice(1:coverage_limit)

    # For a single dimension we skip to the next level
    if (nrow(table) == 1 && table$cum_share[1] == 1) return(NULL)

  } else if (summarization %in% c("average")) {

    if (is.null(total)) {
      total <- table %>%
        dplyr::summarise(total = mean(change, na.rm = TRUE)) %>%
        as.numeric()
    }

    table <- table %>%
      dplyr::mutate(share = abs_change/total) %>%
      dplyr::mutate(cum_share = cumsum(abs(share))/(max(abs(share)) - min(abs(share)))) %>%
      dplyr::filter(cumsum(dplyr::lag(cum_share >= coverage*4, default = FALSE)) == 0) %>%
      dplyr::slice(1:coverage_limit)
  }

  n_outliers <- nrow(table)

  outlier_levels <- table %>%
    dplyr::select(dplyr::all_of(dimension)) %>%
    as.matrix() %>%
    as.character()

  outlier_curr_volume <- table %>%
    dplyr::select(curr_volume) %>%
    as.matrix() %>%
    as.numeric() %>%
    round(1)

  outlier_prev_volume <- table %>%
    dplyr::select(prev_volume) %>%
    as.matrix() %>%
    as.numeric() %>%
    round(1)

  trend <- table %>%
    dplyr::select(trend) %>%
    as.matrix() %>%
    as.character()

  outlier_change <- table %>%
    dplyr::select(change) %>%
    as.matrix() %>%
    as.numeric() %>%
    round(1)

  outlier_change_p <- table %>%
    dplyr::select(change_p) %>%
    as.matrix() %>%
    as.character()

  output <- list(
    n_outliers = n_outliers,
    outlier_levels = outlier_levels,
    outlier_curr_volume = outlier_curr_volume,
    outlier_prev_volume = outlier_prev_volume,
    trend = trend,
    outlier_change = outlier_change,
    outlier_change_p = outlier_change_p
  )

  return(output)
}



